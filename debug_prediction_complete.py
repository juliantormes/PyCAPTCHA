#!/usr/bin/env python3
import torch
import torch.nn as nn
from model.model import captcha_model, model_resnet
from data.dataset import lst_to_str, str_to_lst
from PIL import Image
import torchvision.transforms as transforms

print("ğŸ” Debugging predicciÃ³n completa del pipeline...")

def create_vocab():
    """Crear el vocabulario basado en la funciÃ³n str_to_lst"""
    vocab = ""
    # NÃºmeros 0-9 (Ã­ndices 0-9)
    for i in range(10):
        vocab += str(i)
    # Letras minÃºsculas a-z (Ã­ndices 10-35)
    for i in range(26):
        vocab += chr(ord('a') + i)
    # Letras mayÃºsculas A-Z (Ã­ndices 36-61)
    for i in range(26):
        vocab += chr(ord('A') + i)
    return vocab

def test_complete_pipeline():
    """AnÃ¡lisis completo del pipeline de predicciÃ³n"""
    
    # 1. Crear vocabulario y verificar
    CHARS = create_vocab()
    print(f"ğŸ“š Vocabulario CHARS: {CHARS}")
    print(f"ğŸ“ Longitud vocabulario: {len(CHARS)}")
    
    # Mapear algunos caracteres importantes
    z_idx = CHARS.index('z') if 'z' in CHARS else -1
    e_idx = CHARS.index('e') if 'e' in CHARS else -1
    o_idx = CHARS.index('o') if 'o' in CHARS else -1
    
    print(f"ğŸ¯ Ãndices problemÃ¡ticos: z={z_idx}, e={e_idx}, o={o_idx}")
    
    # 2. Cargar modelo
    print("ğŸ¤– Cargando modelo...")
    model_path = 'models/03_specialized_sssalud/model.pth'
    checkpoint = torch.load(model_path, map_location='cpu')
    
    backbone = model_resnet()
    model = captcha_model(backbone)
    model.load_state_dict(checkpoint['state_dict'])
    model.eval()
    
    print(f"âœ… Modelo cargado - Epoch: {checkpoint.get('epoch', 'N/A')}")
    
    # 3. Cargar y procesar imagen
    print("ğŸ–¼ï¸ Procesando imagen...")
    image_path = 'assets/captcha.png'
    image = Image.open(image_path).convert('RGB')
    
    # Usar las mismas transformaciones que el dataset original
    transform = transforms.Compose([
        transforms.Resize((64, 224)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    image_tensor = transform(image).unsqueeze(0)
    print(f"ğŸ“ Tensor shape: {image_tensor.shape}")
    print(f"ğŸ“Š Tensor range: [{image_tensor.min():.3f}, {image_tensor.max():.3f}]")
    
    # 4. PredicciÃ³n
    print("ğŸ¯ Ejecutando predicciÃ³n...")
    with torch.no_grad():
        output = model(image_tensor)
    
    print(f"ğŸ“¤ Output shape: {output.shape}")
    print(f"ğŸ“ˆ Output range: [{output.min():.3f}, {output.max():.3f}]")
    
    # 5. Aplicar softmax y analizar probabilidades
    print("ğŸ§® Analizando probabilidades...")
    
    # El output deberÃ­a ser [batch_size, 6, 62]
    if len(output.shape) == 3 and output.shape[1:] == (6, 62):
        print("âœ… Forma de output correcta")
    else:
        print(f"âŒ Forma incorrecta: esperada (1, 6, 62), obtenida {output.shape}")
    
    softmax = torch.nn.Softmax(dim=2)
    probs = softmax(output)
    
    # 6. Decodificar predicciÃ³n
    print("\nğŸ”¤ ANÃLISIS POR POSICIÃ“N:")
    prediction = ""
    
    for pos in range(6):
        pos_probs = probs[0, pos, :]
        
        # Obtener top 5 predicciones
        top_probs, top_indices = torch.topk(pos_probs, 5)
        
        predicted_idx = top_indices[0].item()
        predicted_char = CHARS[predicted_idx]
        prediction += predicted_char
        
        print(f"\n  PosiciÃ³n {pos}:")
        print(f"    ğŸ¯ PredicciÃ³n: '{predicted_char}' (conf: {top_probs[0]:.4f})")
        print(f"    ğŸ“‹ Top 5:")
        
        for i in range(5):
            char = CHARS[top_indices[i].item()]
            prob = top_probs[i].item()
            print(f"      {i+1}. '{char}': {prob:.4f}")
        
        # Verificar si los caracteres problemÃ¡ticos tienen alta probabilidad
        if z_idx >= 0:
            z_prob = pos_probs[z_idx].item()
            if z_prob > 0.1:  # Si z tiene mÃ¡s del 10% de probabilidad
                print(f"    âš ï¸  'z' tiene probabilidad alta: {z_prob:.4f}")
        
        if e_idx >= 0:
            e_prob = pos_probs[e_idx].item()
            if e_prob > 0.1:
                print(f"    âš ï¸  'e' tiene probabilidad alta: {e_prob:.4f}")
                
        if o_idx >= 0:
            o_prob = pos_probs[o_idx].item()
            if o_prob > 0.1:
                print(f"    âš ï¸  'o' tiene probabilidad alta: {o_prob:.4f}")
    
    print(f"\nğŸ‰ PREDICCIÃ“N FINAL: '{prediction}'")
    
    # 7. Comparar con la funciÃ³n lst_to_str del dataset
    print("\nğŸ” Verificando funciÃ³n lst_to_str...")
    
    # Simular lo que hace lst_to_str
    pred_indices = []
    for pos in range(6):
        pos_probs = probs[0, pos, :]
        pred_idx = torch.argmax(pos_probs).item()
        pred_indices.append(pred_idx)
    
    lst_str_result = lst_to_str(pred_indices)
    print(f"ğŸ“ lst_to_str resultado: '{lst_str_result}'")
    
    if prediction == lst_str_result:
        print("âœ… Ambos mÃ©todos coinciden")
    else:
        print("âŒ Los mÃ©todos difieren - hay un problema en la decodificaciÃ³n")
    
    return prediction, lst_str_result

if __name__ == '__main__':
    pred1, pred2 = test_complete_pipeline()
